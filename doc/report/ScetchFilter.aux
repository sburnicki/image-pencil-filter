\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mainPaper}
\citation{mainPaper}
\citation{mainPaper}
\citation{Lu:2010:IPS}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  TODO}}{1}{figure.1}}
\newlabel{fig:teaser}{{1}{1}{TODO}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Previous Work}{1}{section.2}}
\citation{Benard:2012:ASC}
\citation{journals/tog/LiuTFDA05}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{2}{section.3}}
\newlabel{method}{{3}{2}{Method}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Line Scetching}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {paragraph}{Gradient Image}{2}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{Line Convolution Filter}{2}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Shading}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {paragraph}{Histogram Matching}{2}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Textureing}{2}{section*.5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}GPU Implementation}{2}{section.4}}
\newlabel{gpu-implementation}{{4}{2}{GPU Implementation}{section.4}{}}
\newlabel{disparity-estimation}{{4}{2}{Disparity Estimation}{section*.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Disparity Estimation}{2}{section*.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The results of the disparity estimation is compared of a state of the art dataset provided by the MPEG group for testing. Again the results of the proposed method is more stable in time. Less holes are randomly appearing and disappearing compared to MPEG data set.}}{3}{figure.2}}
\newlabel{fig:disparity}{{2}{3}{The results of the disparity estimation is compared of a state of the art dataset provided by the MPEG group for testing. Again the results of the proposed method is more stable in time. Less holes are randomly appearing and disappearing compared to MPEG data set}{figure.2}{}}
\newlabel{colorization}{{4}{3}{Colorization and Scribble Propagation}{section*.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Colorization and Scribble Propagation}{3}{section*.7}}
\newlabel{up-sampling}{{4}{3}{Depth up-sampling}{section*.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Depth up-sampling}{3}{section*.8}}
\newlabel{saliency}{{4}{3}{Saliency}{section*.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Saliency}{3}{section*.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Low resolution and extremely noisy depth maps from a Microsoft Kinect is up-sampled and filled (white holes) using the same joint filtering operation as it is used for the optical flow calculation. The image data from the Kinect camera is used for the domain transform.}}{3}{figure.3}}
\newlabel{fig:depth-upsampling}{{3}{3}{Low resolution and extremely noisy depth maps from a Microsoft Kinect is up-sampled and filled (white holes) using the same joint filtering operation as it is used for the optical flow calculation. The image data from the Kinect camera is used for the domain transform}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces First three images show the per frame saliency calculation, which are then temporally filtered to create the smooth results on the right.}}{3}{figure.4}}
\newlabel{fig:saliency}{{4}{3}{First three images show the per frame saliency calculation, which are then temporally filtered to create the smooth results on the right}{figure.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Performance}{3}{section.5}}
\newlabel{performance}{{5}{3}{Performance}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Future Work}{3}{section.6}}
\newlabel{future-work}{{6}{3}{Future Work}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{3}{section.7}}
\bibstyle{alpha}
\bibdata{bibliography}
\bibcite{Benard:2012:ASC}{BLC{$^{+}$}12}
\bibcite{GastalOliveira2011DomainTransform}{GO11}
\bibcite{Lu:2010:IPS}{LSF10}
\bibcite{journals/tog/LiuTFDA05}{LTF{$^{+}$}05}
\bibcite{mainPaper}{LXJ12}
\bibcite{paris2009bilateral}{PKT09}
\bibcite{Rhemann:2011:FCF:2191740.2191908}{RHB{$^{+}$}11}
\bibcite{conf/iccv/VolzBVZ11}{VBVZ11}
\bibcite{Weickert:1998}{Wei98}
\bibcite{Zimmer:2011:OFH:1969654.1969711}{ZBW11}
